# chapter 2

*Describe the work you have done this week and summarize your learning.*

- Describe your work and results clearly. 
- Assume the reader has an introductory course level understanding of writing and reading R code as well as statistical methods.
- Assume the reader has no previous knowledge of your data or the more advanced methods you are using.


**Analysis**

**1.** 

The data constists of questions related to learning statistics.
The data consists of 166 observations of 7 variables after structuring it in the data wrangling part. There is one Factor-variable (categorical measurement), "gender", and the other ones are integer variables or numerical variables. Since the variables  (deep, stra, surf) are combinations of questions measured on Likert-scale, the nature of the variables can be interpreted as a constant variables, in a practical sense, despite of their original measurement in ordinal scale. Age is a ratio-scaled measurement, as it seems to be the case with the Points-variable as well.

Mean age of the respondents is 25,51 years, with minimum of 17, and maximum 55 years. Only ~1/3 of the respondents are men.

codes used: `str(learning2014)`
            `summary(learning2014)`
            `dim(learning2014)`
            `head(learning2014)`
            
            
**2.** 

As mentioned above, mean age of the respondents is 25,51 years, with minimum of 17, and maximum 55 years. Only ~1/3 of the respondents are men. On the basis of summary tables below, it seems that the "Age" variable is not normally distributed, but has some skewness on the left. It can be seen by examining the quartiles of the variable. It is also possible that the maximum value 55 is an outlier in the dataset. Median value of age (22) as well favours this interpretation, that the values close to 55 are relatively  scarce.

gender       Age           Attitude          deep            stra      
 F:110   Min.   :17.00   Min.   :14.00   Min.   :1.583   Min.   :1.250  
 M: 56   1st Qu.:21.00   1st Qu.:26.00   1st Qu.:3.333   1st Qu.:2.625  
         Median :22.00   Median :32.00   Median :3.667   Median :3.188  
         Mean   :25.51   Mean   :31.43   Mean   :3.680   Mean   :3.121  
         3rd Qu.:27.00   3rd Qu.:37.00   3rd Qu.:4.083   3rd Qu.:3.625  
         Max.   :55.00   Max.   :50.00   Max.   :4.917   Max.   :5.000  
      surf           Points     
 Min.   :1.583   Min.   : 7.00  
 1st Qu.:2.417   1st Qu.:19.00  
 Median :2.833   Median :23.00  
 Mean   :2.787   Mean   :22.72  
 3rd Qu.:3.167   3rd Qu.:27.75  
 Max.   :4.333   Max.   :33.00
 
 To have a closer look of distributions, a histogram command can be used:
 
`hist(learning2014$Age)`
`hist(learning2014$Attitude)`
`hist(learning2014$deep)`
`hist(learning2014$stra)`
`hist(learning2014$surf)`
`hist(learning2014$Points)`

Exploring histograms, it can be noticed, that the distribution of "Age" is clearly skewed to the left and that there are only sporadic cases of respondents with the age above 40 years. Other variables are relatively normally distributed, variable "deep" having a small "tail" at the bottom of scale.

Next, the command `pairs(learning2014)` is utilized to have a more nuanced understanding of the dispersion of variables and their bivariate connections with each other. The code is utilized as follows:


`p <- ggpairs(learning2014, mapping = aes(), lower = list(combo = wrap("facethist", bins = 20)))`
`p`


The distribution graphs seems much more nuanced than the ones produced with simple histogram command, but the interpretations of distributions remain in-line with the ones presented above.

At the first row of graphics printed, there are box plot diagrams presenting summary information of a categorial variable "gender" and its connections to other variables in the data. It seems that the largest differences between females and males in the data relates to attitudes towards learning statistics.
It seems that there may exist certain outliers in the data that can be seen from bivariate graphs. On the first row (gender), there seem to be an outlier in deep questions and in Points. In addition, an outlier can be detected in the dispersion cloud printed between "surf" and "deep", from the bottom left of the scatter plot in question.

The strongest correlation exists between Attitude and Points (0,437) and the second strongest, negative by it's direction, exist between "deep" and "surf" (-0,324). This means that learning attitude and exam points are in a close relationship with each other, as does deep and surface questions, but the latter ones correlate in a negative manner. There is only a very weak correlation between Attitude and Age (0,0222), which propably is not statistically significant correlation in the data with only 166 observations.


**3.** 

Multivariate linear regression model with three explanatory variables was fitted using the code:

`my_model <- lm(Points ~ Attitude + stra + surf ,data = learning2014)`
`summary(my_model)`


producing a following summary:


Residuals:
     Min       1Q   Median       3Q      Max 
-17.1550  -3.4346   0.5156   3.6401  10.8952 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.01711    3.68375   2.991  0.00322 ** 
Attitude     0.33952    0.05741   5.913 1.93e-08 ***
stra         0.85313    0.54159   1.575  0.11716    
surf        -0.58607    0.80138  -0.731  0.46563    
---
Signif. codes:  0 ‘* * * ’ 0.001 ‘* * ’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.296 on 162 degrees of freedom
Multiple R-squared:  0.2074,	Adjusted R-squared:  0.1927 
F-statistic: 14.13 on 3 and 162 DF,  p-value: 3.156e-08


In the model above, there is a statistically significant connection between Attitude and the exam points (p = 0). This means that the null hypothesis assuming beta parameter in question to be zero, can be rejected. Instead, strategic questions and surface questions do not have statistically significant connection with exam points, so the null hypothesis in their cases stay valid. In the case of "surf", a standard error of the estimate is even bigger than the value of an estimate itself, which highlights the weakness of the statistical relationship between surf and points, that is, there is no statistically significant relationship.

To get a more parsimonious model (a model that provides an adequate fit to data with the fewest number of parameters), previous linear model is fitted without stra and surf vardiables, which were not statistically significant predictors of exam points. For this task, following code is executed:

`y_model2 <- lm(Points ~ Attitude ,data = learning2014)`
`summary(my_model2)`

producing a following summary: 


Residuals:
     Min       1Q   Median       3Q      Max 
-16.9763  -3.2119   0.4339   4.1534  10.6645 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.63715    1.83035   6.358 1.95e-09 * * *
Attitude     0.35255    0.05674   6.214 4.12e-09 * * *
--
Signif. codes:  0 ‘* * * ’ 0.001 ‘* * ’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 5.32 on 164 degrees of freedom
Multiple R-squared:  0.1906,	Adjusted R-squared:  0.1856 
F-statistic: 38.61 on 1 and 164 DF,  p-value: 4.119e-09



**4.** 

According to the model presented above, attitude towards learning statistics have a strong univariate statistical associaton with exam points. The null hypothesis related to the estimate of "Attitude" can be rejected. The unstandardized estimate value 0,35255 of the variable "Attitude", means that when the value of "Attitude" increases one unit, the value of dependent variable "exam points" increases ~0,35 units.

The omnibus F-test for testing the hypothesis that all regression coefficients are zero, has a very low p-value (4.119e-09), stating that not all coefficients in the model are zero. This is not surprising, because there is only one coefficient included in the model, which was already proven to be a significant predictor.

The square of the multiple correlation coefficient is 0,1906, meaning that the model presented above, with only one explanatory variable, Attitude, account for about 19 % of the variation in exam points in the learning2014 data.


**5.** 

The following codes were executed for graphical model validation:

`plot(my_model2, which = c(1))` for residuals vs. fitted values
`plot(my_model2, which = c(2))` for normal QQ plots
`plot(my_model2, which = c(5))` for residuals vs. Leverage.


In addition to assumption of linearity between target variable and model parameters, it is also assumed that the errors of the linear regression model are normally distributed. It is also assumed that the errors are not correlated and they have constant variance. In addition, the latter implies that the size of a given error doesn't depend on the explanatory variable.

Based on Normal QQ-plot (see the codes above), it can be noticed that there is a reasonable fit of the residuals with the line. There is a slight deviation downwards from the line at the both ends of the line, though, which must be taken into account. Thus, the normality assumption might finally be a slighlty questionable.

The graph of "Residuals vs. Fitted" shows a scatter plot with no clear patterns to perceive. In other words, there is a reasonably random spread of points in the graph, apart from few single points at the bottom of the scatter plot. This indicates, that the size of errors does not depend on the explanatory variable and that the errors do have a constant variance.

Based on "Residuals vs. Leverage" graph, it seems that there are no single observation with significantly more leverage than others, because the scatter plot is quite randomly dispersed. This means that no single observation with unusually high impact in the model can be detected. Thus, the model seems quite valid with the assumptions fulfilled in a reasonable way.

